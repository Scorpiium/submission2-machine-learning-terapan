# -*- coding: utf-8 -*-
"""Submission 2_Machine Learning Terapan.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WxI4Q0r64oZAtiDP8ixAjl_Z1z-Xta0h

Muhammad Fathi Radithya // MC006D5Y1315

Submission Sistem Rekomendasi

### Import Library
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""- `numpy`: Library untuk komputasi numerik dan operasi array multidimensi.
- `matplotlib.pyplot`: Modul untuk membuat visualisasi dasar seperti grafik garis dan batang.
- `pandas`: Digunakan untuk manipulasi dan analisis data tabular (seperti DataFrame).
- `seaborn`: Library visualisasi berbasis matplotlib yang lebih estetis dan mudah digunakan untuk eksplorasi data statistik.

- `sklearn.model_selection.train_test_split`: Fungsi untuk membagi dataset menjadi data pelatihan dan pengujian.
- `sklearn.feature_extraction.text.TfidfVectorizer`: Digunakan untuk mengubah data teks menjadi representasi vektor numerik berbasis TF-IDF (Term Frequency–Inverse Document Frequency).

- `tensorflow`, `keras`, dan `tensorflow.keras.layers`: Library deep learning untuk membangun dan melatih model neural network. Keras adalah antarmuka tingkat tinggi dari TensorFlow yang memudahkan pembuatan model secara modular dan fleksibel.

### Data Loading
"""

movies = pd.read_csv('movies.csv')
ratings = pd.read_csv('ratings.csv')

"""Memuat dua dataset utama yang akan digunakan dalam sistem rekomendasi:

- `movies.csv`: Berisi informasi film, termasuk:
  - `movieId`: ID unik untuk tiap film.
  - `title`: Judul film beserta tahun rilis.
  - `genres`: Daftar genre untuk setiap film, dipisahkan dengan tanda `|`.

- `ratings.csv`: Berisi data rating yang diberikan pengguna terhadap film, termasuk:
  - `userId`: ID unik pengguna.
  - `movieId`: ID film yang dinilai.
  - `rating`: Nilai rating (biasanya antara 0.5 hingga 5.0).
  - `timestamp`: Waktu rating diberikan (dalam format UNIX timestamp).

Data dimuat menggunakan fungsi `pd.read_csv()` dari library `pandas`, dan disimpan dalam variabel `movies` dan `ratings` dalam bentuk `DataFrame`.

### Data Understanding
"""

print('Jumlah data film: ', len(movies.movieId.unique()))
print('Jumlah data reviewer: ', len(ratings.userId.unique()))
print('Jumlah data rating: ', len(ratings))

"""- **Jumlah data film**: Dihitung berdasarkan jumlah nilai unik pada kolom `movieId` di `movies`. Menunjukkan berapa banyak film berbeda yang tersedia dalam dataset.

- **Jumlah data reviewer (pengguna)**: Dihitung dari nilai unik pada kolom `userId` di `ratings`. Menunjukkan jumlah pengguna unik yang telah memberikan rating terhadap film.

- **Jumlah data rating**: Dihitung dari panjang baris `ratings` secara keseluruhan. Mewakili total interaksi user-film dalam bentuk rating (termasuk kemungkinan rating ganda dari pengguna berbeda terhadap film yang sama).
"""

movies.info()

"""Pada tahap ini, dilakukan eksplorasi awal terhadap data untuk memahami struktur dan isi dari dataset `movies`. Dataset terdiri dari 9742 baris data dan 3 kolom fitur.

- `movieId`: ID unik untuk tiap film.
- `title`: Judul film beserta tahun rilis.
- `genres`: Daftar genre untuk setiap film, dipisahkan dengan tanda `|`.
"""

movies.head()

ratings.info()

"""Pada tahap ini, dilakukan eksplorasi awal terhadap data untuk memahami struktur dan isi dari dataset `ratings`. Dataset terdiri dari 100836 baris data dan 4 kolom fitur.

- `userId`: ID unik pengguna.
- `movieId`: ID film yang dinilai.
- `rating`: Nilai rating (biasanya antara 0.5 hingga 5.0).
- `timestamp`: Waktu rating diberikan (dalam format UNIX timestamp).
"""

ratings.head()

"""### Univariate Exploratory Data Analysis"""

all_genres = movies['genres'].str.split('|').explode()

unique_genres = all_genres.unique()

print('Banyak tipe genre unik:', len(unique_genres))
print('Tipe genre unik:', unique_genres)

"""Analisis berikut dilakukan untuk mengetahui **berapa banyak jenis genre film unik** yang terdapat dalam dataset `movies`, serta menampilkan semua nama genre tersebut.

- **`movies['genres'].str.split('|')`**: Memecah isi kolom `genres` yang awalnya berupa string gabungan seperti `'Adventure|Fantasy|Comedy'` menjadi list genre:  
contoh: `'Comedy|Romance'` → `['Comedy', 'Romance']`.

- **`.explode()`**: Mengubah setiap elemen list hasil pemisahan menjadi baris terpisah. Misalnya, 1 baris dengan 3 genre akan menjadi 3 baris, masing-masing dengan 1 genre.

- **`unique_genres = all_genres.unique()`**: Mengambil nilai-nilai unik dari semua genre yang telah dipisahkan dan di-"explode".

- **`print(...)`**: Menampilkan
     - Jumlah genre unik yang ditemukan (`len(unique_genres)`).
     - Daftar nama semua genre unik (`unique_genres`).
"""

plt.figure(figsize=(12, 6))
sns.set_style("whitegrid")

sns.countplot(x=all_genres, order=all_genres.value_counts().index)

plt.title('Distribusi Genre Film', fontsize=16)
plt.xlabel('Jumlah Film')
plt.xticks(rotation=45)
plt.ylabel('Genre')
plt.tight_layout()
plt.show()

"""Berdasarkan persebaran plot genre film dalam dataset `movies`, dapat disimpulkan bahwa Film dengan genre `Drama` dan `Comedy` paling umum, mungkin menunjukkan minat pengguna yang tinggi."""

plt.figure(figsize=(10, 6))
sns.set_style("whitegrid")

sns.countplot(x=ratings['rating'], order=sorted(ratings['rating'].unique()))

plt.title('Distribusi Rating Film oleh Pengguna', fontsize=16)
plt.xlabel('Rating')
plt.ylabel('Jumlah')
plt.tight_layout()
plt.show()

"""Berdasarkan persebaran plot rating film dalam dataset `ratings`. Sebagian besar rating berada diantara `3.0` dan `4.0`, dengan rating `5.0` setelahnya. Hal ini menunjukkan pengguna yang cenderung memiliki opini positif terhadap film yang mereka tonton.

### Data Preprocessing
"""

all_movies_name = pd.merge(ratings, movies, on='movieId', how='left')
all_movies_name

"""Preprocessing data dilakukan sebagai persiapan TF-IDF vectoring, dimana dapat menghasilkan dataframe `all_movies_name` yang lebih lengkap dan fleksibel untuk preparation berikutnya.

- `pd.merge(...)`: Fungsi dari pandas untuk menggabungkan dua DataFrame.
- `ratings`: Data utama yang berisi informasi pengguna dan rating.
- `movies`: Data tambahan yang berisi detail film (judul dan genre).
- `on='movieId'`: Kolom kunci yang digunakan untuk mencocokkan baris dari kedua DataFrame.
- `how='left'`: Menggunakan metode left join, yang berarti, semua baris dari ratings akan dipertahankan.
"""

all_movies_name.info()

"""### Data Preparation

#### Menangani Missing Value
"""

all_movies_name.isnull().sum()

"""Dari 100836 baris dan 6 kolom pada dataframe `all_movies_name` tidak terdapat kolom yang memiliki missing value, menunjukkan dataframe lengkap untuk seluruh datanya setelah penggabungan.

#### Membersihkan Dataframe
"""

all_movies_name[all_movies_name['genres'] == '(no genres listed)']

all_movies_name[all_movies_name['title'] == 'Green Room (2015)']

"""Sebelumnya pada Univariate Data Exploration, diketahui ada sampel kecil dari film dalam dataset yang tidak memiliki genre, atau `(no genres listed)`. Dalam tahap preparation, dilakukan pengecekan untuk mengetahui dimana saja dan apa yang bisa kita lakukan untuk mengatasinya.

Dalam pengecekan, ditemukan beberapa judul yang tidak memiliki masukan genre, sebagai contoh, `Green Room (2015)` dan `Pirates of the Caribbean: Dead Men Tell No Tales (2017)`. Hal berikut disayangkan, namun dikarenakan jumlah judul yang insignifikan dibandingkan dengan keseluruhan, maka akan dilakukan penghapusan saja.


Selain itu, genre adalah fitur penting dalam sistem rekomendasi, digunakan sebagai fitur utama dalam model berbasis konten seperti TF-IDF vectorization. Data tanpa genre berarti tidak bisa diwakili dalam ruang fitur, dan akan menyebabkan masalah dalam vektorisasi atau prediksi model.
"""

all_movies_name = all_movies_name[all_movies_name['genres'] != '(no genres listed)']
all_movies_name

"""Setelah proses penghapusan, terjadi pengurangan baris dalam dataframe `all_movies_name` dari 100836 menjadi 100789 atau pengurangan sebesar <1%.

#### Normalisasi Teks
"""

all_movies_name['processed_genres'] = (
    all_movies_name['genres']
    .str.replace(r'\|', ' ', regex=True)
    .str.replace('-', '_', regex=True)
    .str.lower()
)
all_movies_name

"""Normalisasi teks dilakukan untuk mempersiapkan data genre agar dapat digunakan dalam proses vektorisasi seperti **TF-IDF**, yang memerlukan input dalam bentuk teks bersih dan konsisten.

- `.str.replace(r'\|', ' ', regex=True)`: Mengganti pemisah antar genre dari '|' menjadi spasi.
- `.str.replace('-', '_', regex=True)`: Mengganti pemisah dalam genre dari '-' menjadi underscore '_', mencegah genre majemuk seperti 'Sci-Fi' atau 'Film-Noir' terpecah menjadi dua kata saat tokenisasi.

#### Penghapusan Duplikat
"""

preparation_tfidf = all_movies_name.drop_duplicates('movieId')
preparation_tfidf

"""Sistem rekomendasi berbasis konten seperti TF-IDF hanya memerlukan satu representasi unik untuk setiap item (dalam hal ini, film). Namun, dataset `all_movies_name` yang merupakan hasil penggabungan antara `ratings` dan `movies` bersifat redundan, karena satu film bisa muncul berkali-kali (setiap kali di-rating oleh pengguna berbeda).

Untuk itu, perlu menghapus baris-baris duplikat berdasarkan kolom `movieId`, sehingga hanya tersisa satu baris representatif per film.

#### Ekstraksi Fitur dan Metadata
"""

movie_id = preparation_tfidf['movieId'].tolist()
movie_title = preparation_tfidf['title'].tolist()
movie_genre = preparation_tfidf['processed_genres'].tolist()

print(len(movie_id))
print(len(movie_title))
print(len(movie_genre))

"""Esktraksi fitur dilakukan untuk **mengambil data penting dari DataFrame `preparation_tfidf` dan mengubahnya menjadi list Python** agar dapat digunakan dalam proses vektorisasi dan pemodelan.

- `movie_id = preparation_tfidf['movieId'].tolist()`: Mengubah kolom movieId menjadi list.
- `movie_title = preparation_tfidf['title'].tolist()`: Mengubah kolom title menjadi list.
- `movie_genre = preparation_tfidf['processed_genres'].tolist()`: Mengubah kolom genre menjadi list, digunakan sebagai input utama dalam proses vektorisasi TF-IDF.
"""

movie_new = pd.DataFrame({
    'id': movie_id,
    'movie_title': movie_title,
    'genres': movie_genre
})
movie_new

"""Memuat ketiga data penting sebelumnya menjadi dataframe baru, yang akan digunakan dalam pemodelan."""

data = movie_new
data.sample(5)

"""### Model Development

#### Content-Based Filtering

##### TF-IDF Vectoring
"""

from sklearn.feature_extraction.text import TfidfVectorizer

tfidf_vectorizer = TfidfVectorizer()
tfidf_vectorizer.fit(data['genres'])

tfidf_vectorizer.get_feature_names_out()

tfidf_matrix = tfidf_vectorizer.fit_transform(data['genres'])
tfidf_matrix.shape

"""Pada tahap ini, dilakukan transformasi teks genre menjadi **representasi numerik** menggunakan **TF-IDF (Term Frequency-Inverse Document Frequency)**, yang umum digunakan dalam sistem rekomendasi berbasis konten.

- Vektor TF-IDF berhasil menangkap 19 genre unik dari data teks yang telah diproses (processed_genres).
  - Genre seperti `sci-fi` dan `film-noir` sebelumnya telah ditransformasikan menjadi `sci_fi` dan `film_noir` agar tidak terpecah saat tokenisasi.
- Matriks TF-IDF memiliki 9690 baris (film) dan 19 kolom (genre).
  - Setiap baris merepresentasikan sebuah film, dan setiap kolom menyatakan nilai bobot TF-IDF dari sebuah genre untuk film tersebut.

Jumlah film (9690) adalah hasil akhir setelah proses penghapusan film dengan genre (no genres listed) yang dilakukan sebelumnya. Film tanpa genre tidak dapat direpresentasikan secara akurat dalam sistem rekomendasi berbasis konten, sehingga dihapus dari data pelatihan.

Dari total awal 9742 film, hanya 9690 yang memiliki genre yang valid, dan digunakan untuk membentuk representasi vektor TF-IDF.
"""

tfidf_matrix.todense()

pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf_vectorizer.get_feature_names_out(),
    index=data.movie_title
).sample(19, axis=1).sample(10, axis=0)

"""Berdasarkan hasil vektor matriks TF-IDF, menghasilkan hubungan `movie_title` dengan `genres` dalam range [0,1]. Semakin mendekati nilai dengan 1, maka semakin kuat korelasinya.

##### Cosine Similarity
"""

from sklearn.metrics.pairwise import cosine_similarity

cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

cosine_sim_df = pd.DataFrame(cosine_sim, index=data['movie_title'], columns=data['movie_title'])
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(5, axis=1).sample(10, axis=0)

"""Cosine Similarity dilakukan untuk mengukur korelasi antara `movie_title` dalam skala [0,1], semakin mendekati 1, semakin kuat korelasinya.

##### Mendapatkan Rekomendasi
"""

def movie_recommendations(judul_film, similarity_data=cosine_sim_df, items=data[['movie_title', 'genres']], k=5):
    if judul_film not in similarity_data.columns:
        print(f"Warning: Film '{judul_film}' not found in similarity data columns.")
        return pd.DataFrame(columns=['movie_title', 'genres'])

    movie_similarity_scores = similarity_data.loc[:, judul_film].to_numpy()

    if len(movie_similarity_scores) < k + 1:
        print(f"Warning: Not enough movies ({len(movie_similarity_scores)}) to recommend {k} items for '{judul_film}'.")
        available_movies_indices = np.argsort(movie_similarity_scores)[::-1]
        seed_index = np.where(similarity_data.columns == judul_film)[0][0]
        available_movies_indices = available_movies_indices[available_movies_indices != seed_index]

        closest_indices = available_movies_indices[:k]
        closest = similarity_data.columns[closest_indices]
        return pd.DataFrame({'movie_title': closest}).merge(items).head(len(closest))


    sorted_indices = np.argsort(movie_similarity_scores)[::-1]

    top_k_plus_1_indices = sorted_indices[:k+1]

    closest = similarity_data.columns[top_k_plus_1_indices]
    closest = closest.drop(judul_film, errors='ignore')

    return pd.DataFrame({'movie_title': closest}).merge(items).head(k)

data[data.movie_title.eq('Your Name. (2016)')]

movie_recommendations('Your Name. (2016)')

"""Model bekerja berdasarkan kemiripan konten, menggunakan TF-IDF vectorization dan cosine similarity.

- Genre film diubah menjadi representasi numerik menggunakan TF-IDF (Term Frequency-Inverse Document Frequency)
- Dibentuk matriks cosine similarity antar film, berdasarkan vektor TF-IDF genre.
- Saat pengguna memberikan judul film (misal `'Your Name. (2016)'`), maka akan:
  - Mengambil skor kemiripan dari film tersebut ke semua film lain.
  - Memilih `k` film yang paling mirip (dengan skor cosine similarity tertinggi).
  - Menyaring hasil agar tidak merekomendasikan film itu sendiri.
  - Mengembalikan daftar film beserta genre-nya sebagai rekomendasi.

##### Evaluasi Kuantitatif
"""

def precision_at_k(recommended, relevant, k):
    recommended_k = recommended[:k]
    relevant_set = set(relevant)
    hit_count = sum(1 for item in recommended_k if item in relevant_set)
    return hit_count / k if k else 0

def recall_at_k(recommended, relevant, k):
    recommended_k = recommended[:k]
    relevant_set = set(relevant)
    hit_count = sum(1 for item in recommended_k if item in relevant_set)
    return hit_count / len(relevant_set) if relevant_set else 0

def evaluate_cbf_model(ratings_df, cosine_sim_df, data_df, k=5, n_users=100):
    users = ratings_df['userId'].unique()
    sampled_users = np.random.choice(users, size=n_users, replace=False)

    precisions, recalls = [], []

    for user in sampled_users:
        user_ratings = ratings_df[(ratings_df['userId'] == user) & (ratings_df['rating'] >= 3.5)]
        relevant_items = user_ratings['movieId'].tolist()

        if not relevant_items:
            continue

        seed_movie_id = user_ratings.sample(1)['movieId'].iloc[0]
        seed_movie_title = data_df[data_df['id'] == seed_movie_id]['movie_title'].values

        if len(seed_movie_title) == 0 or seed_movie_title[0] not in cosine_sim_df.columns:
            continue

        seed_title = seed_movie_title[0]

        recommended_df = movie_recommendations(seed_title, k=k)
        recommended_ids = data_df[data_df['movie_title'].isin(recommended_df['movie_title'])]['id'].tolist()

        p = precision_at_k(recommended_ids, relevant_items, k)
        r = recall_at_k(recommended_ids, relevant_items, k)
        precisions.append(p)
        recalls.append(r)

    mean_p = np.mean(precisions)
    mean_r = np.mean(recalls)

    print(f'Precision@{k}: {mean_p:.4f}')
    print(f'Recall@{k}: {mean_r:.4f}')

evaluate_cbf_model(
    ratings_df=ratings,
    cosine_sim_df=cosine_sim_df,
    data_df=data,
    k=5,
    n_users=100
)

"""- `Precision@5`: 0.0424 (4.24%)

`Precision` digunakan untuk mengukur jumlah film yang benar-benar relevan untuk pengguna. Dalam konteks ini, dari setiap 5 film yang direkomendasikan, rata-rata hanya sekitar 4.24% yang sesuai dengan preferensi pengguna, berdasarkan data histori rating.
- `Recall@5`: 0.0028 (0.28%)

`Recall` digunakan untuk mengukur berapa banyak yang berhasil ditangkap oleh sistem dalam top-K rekomendasi untuk suatu pengguna. Dengan nilai recall sebesar 0.28%, dapat disimpulkan bahwa sistem hanya mampu menjangkau sebagian sangat kecil dari keseluruhan film yang disukai pengguna. Hal ini menunjukkan cakupan (coverage) sistem yang masih rendah.

#### Collaborative Filtering

##### Data Understanding
"""

df = ratings.copy()
df

"""Memuat salinan dari dataframe ratings. Dataframe memiliki 100836 baris dan 4 kolom.

- `userId`: ID unik pengguna.
- `movieId`: ID film yang dinilai.
- `rating`: Nilai rating (biasanya antara 0.5 hingga 5.0).
- `timestamp`: Waktu rating diberikan (dalam format UNIX timestamp).

##### Data Preparation
"""

user_ids = df['userId'].unique().tolist()
movie_ids = df['movieId'].unique().tolist()
print('list userId: ', user_ids)
print('list movieId: ', user_ids)

user_to_user_encoded = {x: i for i, x in enumerate(user_ids)}
movie_to_movie_encoded = {x: i for i, x in enumerate(movie_ids)}
print('encoded userId : ', user_to_user_encoded)
print('encoded movieId : ', movie_to_movie_encoded)

user_encoded_to_user = {i: x for i, x in enumerate(user_ids)}
movie_encoded_to_movie = {i: x for i, x in enumerate(movie_ids)}
print('encoded angka ke userId: ', user_encoded_to_user)
print('encoded angka ke movieId: ', movie_encoded_to_movie)

"""Encoding ID dilakukan untuk mengurutkan `userId` dan `movieId` menjadi indeks berurut. Hal ini digunakan sehingga memudahkan dalam modeling."""

df['user'] = df['userId'].map(user_to_user_encoded)
df['movie'] = df['movieId'].map(movie_to_movie_encoded)

num_users = len(user_to_user_encoded)
print(num_users)

num_movies = len(movie_encoded_to_movie)
print(num_movies)

df['rating'] = df['rating'].values.astype(np.float32)

min_rating = min(df['rating'])
max_rating = max(df['rating'])

print('Number of Users: {}, Number of Films: {}, Min Rating: {}, Max Rating: {}'.format(
    num_users, num_movies, min_rating, max_rating
))

"""Jumlah pengguna dan film dihitung setelah proses encoding untuk menentukan ukuran layer embedding pada model. Rating juga dikonversi ke tipe `float32` agar sesuai dengan kebutuhan pemodelan."""

df = df.drop(columns=['timestamp'])

"""Menghapus kolom `timestamp` karena tidak berkontribusi dalam proses rekomendasi berbasis rating."""

df = df.sample(frac=1, random_state=42)
df

"""Melakukan pengacakan data dengan `sample(frac=1)` untuk memastikan distribusi data lebih merata dan menghindari bias urutan saat pelatihan model. Pengacakan dilakukan secara konsisten menggunakan `random_state=42`.

##### Data Splitting
"""

x = df[['user', 'movie']].values
y = df['rating'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

print(x, y)

"""- Fitur `user` dan `movie` diekstrak sebagai input (x), sedangkan `rating` dinormalisasi ke rentang 0–1 menggunakan rumus min-max scaling agar lebih stabil saat pelatihan model (y).
- Membagi dataset dibagi menjadi dua bagian: 80% untuk pelatihan (x_train, y_train) dan 20% untuk validasi (x_val, y_val) untuk menguji performa model pada data yang belum terlihat. Pembagian ini penting untuk menghindari overfitting dan mengevaluasi generalisasi model.

##### Training
"""

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_movies, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_movies = num_movies
    self.embedding_size = embedding_size
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.user_bias = layers.Embedding(num_users, 1)
    self.movies_embedding = layers.Embedding(
        num_movies,
        embedding_size,
        embeddings_initializer = 'he_normal',
        embeddings_regularizer = keras.regularizers.l2(1e-6)
    )
    self.movies_bias = layers.Embedding(num_movies, 1)

  def call(self, inputs):
    user_vector = self.user_embedding(inputs[:,0])
    user_bias = self.user_bias(inputs[:, 0])
    movies_vector = self.movies_embedding(inputs[:, 1])
    movies_bias = self.movies_bias(inputs[:, 1])

    dot_user_movies = tf.tensordot(user_vector, movies_vector, 2)

    x = dot_user_movies + user_bias + movies_bias

    return tf.nn.sigmoid(x)

"""Model `RecommenderNet` merupakan implementasi collaborative filtering berbasis neural network dengan pendekatan embedding. Di dalamnya, setiap pengguna dan film direpresentasikan dalam bentuk vektor berdimensi tetap `embedding_size` yang dipelajari selama proses pelatihan.

Model terdiri dari dua pasang layer embedding:
- `user_embedding` dan `user_bias` untuk pengguna,
- `movies_embedding` dan `movies_bias` untuk film.

Vektor embedding pengguna dan film digabung menggunakan operasi dot product `tf.tensordot` untuk menangkap interaksi antar-entitas. Nilai bias ditambahkan sebagai koreksi, dan hasil akhir diproses melalui fungsi aktivasi sigmoid untuk mengeluarkan skor prediksi antara 0 hingga 1 (karena rating telah dinormalisasi).
"""

model = RecommenderNet(num_users, num_movies, 50)

model.compile(
    loss = tf.keras.losses.BinaryCrossentropy(),
    optimizer = keras.optimizers.Adam(learning_rate=0.001),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Model dikompilasi menggunakan:
- Fungsi loss `Binary Crossentropy` karena rating telah disesuaikan ke rentang [0, 1],
- Optimizer `Adam` untuk efisiensi pembelajaran,
- Metrik evaluasi `Root Mean Squared Error` (RMSE) yang umum digunakan pada sistem rekomendasi.
"""

history = model.fit(
    x = x_train,
    y = y_train,
    batch_size = 64,
    epochs = 10,
    validation_data = (x_val, y_val)
)

"""Hasil dari `RMSE` pada data training mencapai 0.1965 dan pada data validasi mencapai 0.2041. Model telah menunjukkan kinerja baik dan stabil, dengan nilai RMSE di kisaran 0.20, yang termasuk rendah untuk rating yang telah dinormalisasi. Ini berarti model cukup akurat dalam merekomendasikan film berdasarkan pola rating pengguna sebelumnya.

##### Visualisasi
"""

plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('model_metrics')
plt.ylabel('root_mean_squared_error')
plt.xlabel('epoch')
plt.legend(['train', 'validation'], loc='upper left')
plt.show()

"""Hasil visualisasi menggambarkan evaluasi `RMSE` yang stabil selama pelatihan, menunjukkan pelatihan berjalan dengan normal.

##### Mendapatkan Rekomendasi
"""

movie_df = movie_new
df = pd.read_csv('ratings.csv')

user_id = df.userId.sample(1).iloc[0]
movies_watched_by_user = df[df.userId == user_id]

movies_not_watched = movie_df[~movie_df['id'].isin(movies_watched_by_user.movieId.values)]['id']
movies_not_watched = list(
    set(movies_not_watched)
    .intersection(set(movie_to_movie_encoded.keys()))
)

movies_not_watched = [[movie_to_movie_encoded.get(x)] for x in movies_not_watched]
user_encoder = user_to_user_encoded.get(user_id)
user_movies_array = np.hstack(
    ([[user_encoder]] * len(movies_not_watched), movies_not_watched)
)

ratings = model.predict(user_movies_array).flatten()

top_ratings_indices = ratings.argsort()[-10:][::-1]
recommended_movies_ids = [
    movie_encoded_to_movie.get(movies_not_watched[x][0]) for x in top_ratings_indices
]

print('Showing recommendations for users: {}'.format(user_id))
print('===' * 9)
print('Movies with high ratings from user')
print('----' * 8)

top_movies_user = (
    movies_watched_by_user.sort_values(
        by = 'rating',
        ascending=False
    )
    .head(5)
    .movieId.values
)

movie_df_rows = movie_df[movie_df['id'].isin(top_movies_user)]
for row in movie_df_rows.itertuples():
    print(row.movie_title, ':', row.genres)

print('----' * 8)
print('Top 10 Film Recommendation')
print('----' * 8)

recommended_movies = movie_df[movie_df['id'].isin(recommended_movies_ids)]
for row in recommended_movies.itertuples():
    print(row.movie_title, ':', row.genres)

"""Berdasarkan hasil model, untuk mendapatkan rekomendasi untuk sebuah user akan dilakukan:
1. Menentukan pengguna secara acak.
  - Memilih satu pengguna secara acak dari dataset `ratings`.
  - Mengambil daftar film yang telah ditonton dan diberi rating oleh pengguna tersebut.
2. Menentukan daftar film yang belum ditonton.
3. Mempersiapkan input prediksi untuk model.
4. Melakukan prediksi rating menggunakan model terlatih.
  - Model `RecommenderNet` memprediksi rating yang kemungkinan diberikan user terhadap semua film yang belum ditonton.
5. Mengambil dan menampilkan top 10 rekomendasi tertinggi.
"""